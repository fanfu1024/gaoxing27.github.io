<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>和而不同</title>
  
  <subtitle>五朝</subtitle>
  <link href="https://gaoxing27.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://gaoxing27.gitee.io/"/>
  <updated>2021-06-27T14:16:13.808Z</updated>
  <id>https://gaoxing27.gitee.io/</id>
  
  <author>
    <name>凡夫</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>node-基本原理及工作流程</title>
    <link href="https://gaoxing27.gitee.io/2021/06/16/node-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%8F%8A%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    <id>https://gaoxing27.gitee.io/2021/06/16/node-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%8F%8A%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</id>
    <published>2021-06-16T02:52:33.000Z</published>
    <updated>2021-06-27T14:16:13.808Z</updated>
    
    <content type="html"><![CDATA[<p>Node 是一个服务器端 JavaScript 解释器，可以方便地搭建出响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型，非常适合在分布式设备上运行数据密集型的实时应用。</p><p>Node.js 是一个可以让 JavaScript 运行在浏览器之外的平台，功能完善，它实现了诸如文件系统、模块、包、操作系统 API、网络通信等功能 。</p><h3 id="v8引擎"><a href="#v8引擎" class="headerlink" title="v8引擎"></a>v8引擎</h3><p>V8 JavaScript 引擎是 Google 用于其 Chrome 浏览器的底层 JavaScript 引擎，负责解释并执行代码。Google 使用 V8 创建了一个用 C++ 编写的超快解释器，该解释器拥有另一个独特特征；你可以下载该引擎并将其嵌入任何应用程序。V8 JavaScript 引擎并不仅限于在一个浏览器中运行。因此，Node 实际上会使用 Google 编写的 V8 JavaScript 引擎，并将其重建为可在服务器上使用。</p><h3 id="事件驱动编程"><a href="#事件驱动编程" class="headerlink" title="事件驱动编程"></a>事件驱动编程</h3><p>Java，PHP等编程语言是面向对象编程，Node是事件驱动编程的思想。<br>事件驱动编程，即为需要处理的事件编写相应的事件处理程序，代码在事件发生时执行，当事件触发时被操作系统唤醒，这样能更加有效地使用cpu。<br>事件驱动模型如图：</p><p><img src="/images/node/%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B.png" alt="事件驱动模型"></p><p>事件驱动模型主要包含3个对象：事件源、事件和事件处理程序。</p><ul><li><p>事件源：产生事件的地方(html元素)</p></li><li><p>事件：点击/鼠标操作/键盘操作等等</p></li><li><p>事件对象：当某个事件发生时，可能会产生一个事件对象，该事件对象会封装好该事件的信息，传递给事件处理程序</p></li><li><p>事件处理程序：响应用户事件的代码<br>其实我们使用的window系统也算得上是事件驱动了。</p><p>我们来看一个简单的事例：监听鼠标点击事件，并能够显示鼠标点击的位置x,y。</p></li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">head</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">script</span>&gt;</span> </span><br><span class="line"><span class="javascript">   <span class="function"><span class="keyword">function</span> <span class="title">test1</span>(<span class="params">e</span>)</span>&#123; </span></span><br><span class="line"><span class="javascript">     <span class="built_in">window</span>.alert(<span class="string">&quot;x=&quot;</span>+e.clientX+<span class="string">&quot;y=&quot;</span>+e.clientY); </span></span><br><span class="line">   &#125; </span><br><span class="line">   <span class="tag">&lt;/<span class="name">script</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;/<span class="name">head</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">body</span> <span class="attr">onmousedown</span>=<span class="string">&quot;test1(event)&quot;</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;/<span class="name">body</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span> </span><br></pre></td></tr></table></figure><h3 id="Node-js运行原理分析"><a href="#Node-js运行原理分析" class="headerlink" title="Node.js运行原理分析"></a>Node.js运行原理分析</h3><p>通常应用程序的请求过程可以分为俩个部分：CPU运算和I/O读写，而CPU计算速度通常远高于磁盘读写速度，这就导致CPU运算已经完成，但是不得不等待磁盘I/O任务完成之后再继续接下来的业务，所以I/O才是应用程序的瓶颈所在；在I/O密集型业务中，假设请求需要100ms来完成，其中99ms化在I/O上。如果需要优化应用程序，让他能同时处理更多的请求，我们会采用多线程，同时开启100个、1000个线程来提高我们请求处理，当然这也是一种可观的方案。<br>但是由于一个CPU核心在一个时刻只能做一件事情，操作系统只能通过将CPU切分为时间片的方法，让线程可以较为均匀的使用CPU资源。但当线程数量过多时，时间将会被消耗在上下文切换中。所以在大并发时，多线程结构还是无法做到强大的伸缩性。</p><p>《深入浅出Node》一书提到 “单线程的最大好处，是不用像多线程编程那样处处在意状态的同步问题，这里没有死锁的存在，也没有线程上下文切换所带来的性能上的开销”，那么一个线程一次只能处理一个请求岂不是无稽之谈，先让我们看张图：</p><p><img src="/images/node/node%E6%94%AF%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="node支行流程图"></p><p>Node.js的单线程并不是真正的单线程，只是开启了单个线程进行业务处理（cpu的运算），同时开启了其他线程专门处理I/O。当一个指令到达主线程，主线程发现有I/O之后，直接把这个事件传给I/O线程，不会等待I/O结束后，再去处理下面的业务，而是拿到一个状态后立即往下走，这就是“单线程”、“异步I/O”。</p><p>Node.js的I/O 处理完之后会有一个回调事件，这个事件会放在一个事件处理队列里头，在进程启动时node会创建一个类似于While(true)的循环，它的每一次轮询都会去查看是否有事件需要处理，是否有事件关联的回调函数需要处理，如果有就处理，然后加入下一个轮询，如果没有就退出进程，这就是所谓的“事件驱动”。这也从Node的角度解释了什么是”事件驱动”。<br>在node.js中，事件主要来源于网络请求，文件I/O等，根据事件的不同对观察者进行了分类，有文件I/O观察者，网络I/O观察者。事件驱动是一个典型的生产者/消费者模型，请求到达观察者那里，事件循环从观察者进行消费，主线程就可以马不停蹄的只关注业务不用再去进行I/O等待。</p><blockquote><p>引用</p><p><a href="https://blog.csdn.net/xiangzhihong8/article/details/53954600">https://blog.csdn.net/xiangzhihong8/article/details/53954600</a></p></blockquote>]]></content>
    
    
    <summary type="html">Node 是一个服务器端 JavaScript 解释器，用于方便地搭建响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型而得以轻量和高效，非常适合在分布式设备上运行数据密集型的实时应用。Node.js 是一个可以让 JavaScript 运行在浏览器之外的平台。它实现了诸如文件系统、模块、包、操作系统 API、网络通信等 Core JavaScript 没有或者不完善的功能。历史上将 JavaScript移植到浏览器外的计划不止一个，但Node.js 是最出色的一个。</summary>
    
    
    
    <category term="Node" scheme="https://gaoxing27.gitee.io/categories/Node/"/>
    
    
    <category term="Node" scheme="https://gaoxing27.gitee.io/tags/Node/"/>
    
  </entry>
  
  <entry>
    <title>图解kafka</title>
    <link href="https://gaoxing27.gitee.io/2021/06/15/%E5%9B%BE%E8%A7%A3kafka/"/>
    <id>https://gaoxing27.gitee.io/2021/06/15/%E5%9B%BE%E8%A7%A3kafka/</id>
    <published>2021-06-15T07:47:44.000Z</published>
    <updated>2021-06-30T10:57:05.210Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><p>Kafka 是一套流处理系统，可以让后端服务轻松的相互沟通，是微服务架构中常用的组件。</p><p><img src="/images/kafka/base.jpg" alt="kafka"></p><p>生产者消费者<br>生产者服务 Producer 向 Kafka 发送消息，消费者服务 Consumer 监听 Kafka 接收消息。</p><p><img src="/images/kafka/%E7%94%9F%E4%BA%A7-kafka-%E6%B6%88%E8%B4%B9.jpg" alt="生产-kafka-消费"></p><p>一个服务可以同时为生产者和消费者。</p><p><img src="/images/kafka/%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9%E8%80%85-kafka.png" alt="生产消费者-kafka"></p><h3 id="Topics-主题"><a href="#Topics-主题" class="headerlink" title="Topics 主题"></a>Topics 主题</h3><p>Topic 是生产者发送消息的目标地址，是消费者的监听目标。</p><p><img src="/images/kafka/kafka-topic.png" alt="kafka-topic"></p><p>一个服务可以监听、发送多个 Topics。</p><p><img src="/images/kafka/%E5%8D%95%E4%B8%AA%E6%9C%8D%E5%8A%A1%E7%9B%91%E5%90%AC%E5%A4%9A%E4%B8%AATopics.png" alt="单个服务监听多个Topics"></p><p>Kafka 中有一个【consumer-group（消费者组）】的概念。</p><p>这是一组服务，扮演一个消费者。</p><p><img src="/images/kafka/%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84.png" alt="消费者组"></p><p>如果是消费者组接收消息，Kafka 会把一条消息路由到组中的某一个服务。</p><p><img src="/images/kafka/%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E5%88%B0%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%90%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1.png" alt="路由消息到消费者组中的某一个服务"></p><p>这样有助于消息的负载均衡，也方便扩展消费者。</p><p>Topic 扮演一个消息的队列。</p><p>首先，一条消息发送了。</p><p><img src="/images/kafka/%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%88%B0topic.png" alt="生产消息到topic"></p><p>然后，这条消息被记录和存储在这个队列中，不允许被修改。</p><p><img src="/images/kafka/topic%E4%B8%AD%E7%9A%84%E6%B6%88%E6%81%AF%E4%B8%8D%E5%85%81%E8%AE%B8%E4%BF%AE%E6%94%B9.png" alt="topic中的消息不允许修改"></p><p>接下来，消息会被发送给此 Topic 的消费者。</p><p>但是，这条消息并不会被删除，会继续保留在队列中。</p><p><img src="/images/kafka/%E6%B6%88%E6%81%AF%E5%B9%B6%E4%B8%8D%E4%BC%9A%E8%A2%AB%E5%88%A0%E9%99%A4%EF%BC%8C%E4%BC%9A%E7%BB%A7%E7%BB%AD%E4%BF%9D%E7%95%99%E5%9C%A8%E9%98%9F%E5%88%97.png" alt="消息并不会被删除，会继续保留在队列"></p><p>继续发送消息。</p><p><img src="/images/kafka/%E7%BB%A7%E7%BB%AD%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF.png" alt="继续发送消息"></p><p>像之前一样，这条消息会发送给消费者、不允许被改动、一直呆在队列中。</p><p>（消息在队列中能呆多久，可以修改 Kafka 的配置）</p><p><img src="/images/kafka/a.png" alt="a"></p><p><img src="/images/kafka/b.png" alt="b"></p><h3 id="Partitions-分区"><a href="#Partitions-分区" class="headerlink" title="Partitions 分区"></a>Partitions 分区</h3><p>上面 Topic 的描述中，把 Topic 看做了一个队列，实际上，一个 Topic 是由多个队列组成的，被称为【Partition（分区）】。</p><p>这样可以便于 Topic 的扩展。</p><p><img src="/images/kafka/topic-Partitions.png" alt="topic-Partitions"></p><p>生产者发送消息的时候，这条消息会被路由到此 Topic 中的某一个 Partition。</p><p><img src="/images/kafka/%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%88%B0Topic%E4%B8%AD%E7%9A%84%E6%9F%90%E4%B8%80%E4%B8%AAPartition.png" alt="生产者发送消息到Topic中的某一个Partition"></p><p>消费者监听的是所有分区。</p><p><img src="/images/kafka/%E6%B6%88%E8%B4%B9%E8%80%85%E7%9B%91%E5%90%AC%E7%9A%84%E6%98%AF%E6%89%80%E6%9C%89%E5%88%86%E5%8C%BA.png" alt="消费者监听的是所有分区"></p><p>生产者发送消息时，默认是面向 Topic 的，由 Topic 决定放在哪个 Partition，默认使用轮询策略。</p><p><img src="/images/kafka/%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%94%B1Topic%E5%86%B3%E5%AE%9A%E6%94%BE%E5%9C%A8%E5%93%AA%E4%B8%AAPartition.png" alt="产者发送消息由Topic决定放在哪个Partition"></p><p>也可以配置 Topic，让同类型的消息都在同一个 Partition。</p><p>例如，处理用户消息，可以让某一个用户所有消息都在一个 Partition。</p><p>例如，用户1发送了3条消息：A、B、C，默认情况下，这3条消息是在不同的 Partition 中（如 P1、P2、P3）。</p><p>在配置之后，可以确保用户1的所有消息都发到同一个分区中（如 P1）。</p><p><img src="/images/kafka/%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F%E6%80%A7.png" alt="消息有序性"></p><p>这个功能有什么用呢？</p><p>这是为了提供消息的【有序性】。</p><p>消息在不同的 Partition 是不能保证有序的，只有一个 Partition 内的消息是有序的。</p><p><img src="/images/kafka/%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F%E6%80%A72.png" alt="消息有序性2"></p><p><img src="/images/kafka/%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F%E6%80%A73.png" alt="消息有序性3"></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Kafka 是集群架构的，ZooKeeper是重要组件。</p><p><img src="/images/kafka/kafka-zookeeper.png" alt="kafka-zookeeper"></p><p>ZooKeeper 管理者所有的 Topic 和 Partition。</p><p>Topic 和 Partition 存储在 Node 物理节点中，ZooKeeper负责维护这些 Node。</p><p><img src="/images/kafka/kafka-zookeeper-znode.png" alt="kafka-zookeeper-znode"></p><p>例如，有2个 Topic，各自有2个 Partition。</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B.png" alt="示例.png"></p><p>这是逻辑上的形式，但在 Kafka 集群中的实际存储可能是这样的：</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B2.png" alt="示例2"></p><p>Topic A 的 Partition #1 有3份，分布在各个 Node 上。</p><p>这样可以增加 Kafka 的可靠性和系统弹性。</p><p>3个 Partition #1 中，ZooKeeper 会指定一个 Leader，负责接收生产者发来的消息。</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B3.png" alt="示例3"></p><p>其他2个 Partition #1 会作为 Follower，Leader 接收到的消息会复制给 Follower。</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B4.png" alt="示例4"></p><p>这样，每个 Partition 都含有了全量消息数据。</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B5.png" alt="示例5"></p><p>即使某个 Node 节点出现了故障，也不用担心消息的损坏。</p><p>Topic A 和 Topic B 的所有 Partition 分布可能就是这样的：</p><p><img src="/images/kafka/%E7%A4%BA%E4%BE%8B6.png" alt="示例6"></p><blockquote><p>原文<br>-<a href="https://blog.csdn.net/duysh/article/details/116355977">https://blog.csdn.net/duysh/article/details/116355977</a></p></blockquote>]]></content>
    
    
    <summary type="html">afka 是一套流处理系统，可以让后端服务轻松的相互沟通，是微服务架构中常用的组件。生产者服务 Producer 向 Kafka 发送消息，消费者服务 Consumer 监听 Kafka 接收消息。一个服务可以同时为生产者和消费者。Topic 是生产者发送消息的目标地址，是消费者的监听目标。</summary>
    
    
    
    <category term="kafka" scheme="https://gaoxing27.gitee.io/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gaoxing27.gitee.io/tags/kafka/"/>
    
    <category term="消息队列" scheme="https://gaoxing27.gitee.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="中间件" scheme="https://gaoxing27.gitee.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>简单生活，努力工作，爱自己爱家人</title>
    <link href="https://gaoxing27.gitee.io/2021/06/01/%E7%AE%80%E5%8D%95%E7%94%9F%E6%B4%BB%EF%BC%8C%E5%8A%AA%E5%8A%9B%E5%B7%A5%E4%BD%9C%EF%BC%8C%E7%88%B1%E8%87%AA%E5%B7%B1%E7%88%B1%E5%AE%B6%E4%BA%BA/"/>
    <id>https://gaoxing27.gitee.io/2021/06/01/%E7%AE%80%E5%8D%95%E7%94%9F%E6%B4%BB%EF%BC%8C%E5%8A%AA%E5%8A%9B%E5%B7%A5%E4%BD%9C%EF%BC%8C%E7%88%B1%E8%87%AA%E5%B7%B1%E7%88%B1%E5%AE%B6%E4%BA%BA/</id>
    <published>2021-06-01T10:32:48.000Z</published>
    <updated>2021-06-01T11:59:46.029Z</updated>
    
    <content type="html"><![CDATA[<p>静心平想，其实我是一个很幸运的人，我挺知足。</p><p>上学时代，激情满怀，却资质平庸，成绩上并无高点，但也不是最差，可能这就要感谢一下自己的执着和坚持，所以还是挺幸运的。不要攻击我因为不是最差就沾沾自喜。不是的，我并非沾沾自喜，而是满足。有很些东西是需要天赋和机遇的，我不得不承认，我这两点都没有，是初心不变让我能有所得。我也是在毕业后才慢慢明白，如果非要把人生当作一场比赛，我希望我的比赛是一场马拉松，而不是百米赛跑。我不想一下就耗尽自己的力气，同时也没有来得及去享受加油和呐喊助威。我希望我拼得不是速度，而是耐力。也许我跑的不是最快，不是第一，但是每坚实的跑出一步，都是我对的人生发于心的热爱，我会记住沿途的每一张笑脸和每一个从身边的奔跑过的人。</p><p>最近躺平、内卷，这两个词挺热的，了解完躺平、内卷，我简直下巴要掉到地上了，虽然现在生活好了，同时压力更大了，竞争更激烈，但是通过这种方式来对表达自己的反抗，太愚蠢了。也许目标看似遥不可及，如果躺下了，真就不可及了。</p><p>聪明的人善于计算，以现在的能力再怎么努力，也买不起房子、谈不起恋爱、结不起婚、生得起养不起孩子、上不起医院看不起病……，我感觉这些计算都是错的，这让我想起一个成语故事：刻舟求剑；社会在发展，经济在发展，人也在发展，发展就是变化，既然一切都是在变化中，为什么要用现在来计算未来，这哪是聪明，简直愚蠢；人类已经登上了月球，以后也许还会上火星，以后的以后还有更多的未知和惊喜</p><p>停止焦虑对你的束缚吧，世界上没有一种精密的模型可以计算未来，计算人的潜力，计算人的决心 </p><p>拾起这好时光，决心让自己变简单，让生活变简单，努力爱自己、家人和工作</p>]]></content>
    
    
    <summary type="html">静心平想，其实我是一个很幸运的人，应该知足。 上学时代，激情满怀，却资质平庸，成绩上并无高点，但也不是最差，可能这就要感谢一下自己的执着和坚持，所以还是挺幸运的。不要攻击我因为不是最差就沾沾自喜。不是的，我并非沾沾自喜，而是满足。有很些东西是需要天赋和机遇的，我不得不承认，我这两点都没有，是初心不变让我能有所得。我也是在毕业后才慢慢明白，如果非要把人生当作一场比赛，我希望我的比赛是一场马拉松，而不是百米赛跑。</summary>
    
    
    
    <category term="生活" scheme="https://gaoxing27.gitee.io/categories/life/"/>
    
    
    <category term="生活" scheme="https://gaoxing27.gitee.io/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>dubbo-spring-原理</title>
    <link href="https://gaoxing27.gitee.io/2021/05/28/dubbo-spring-%E9%9B%86%E6%88%90%E5%8E%9F%E7%90%86/"/>
    <id>https://gaoxing27.gitee.io/2021/05/28/dubbo-spring-%E9%9B%86%E6%88%90%E5%8E%9F%E7%90%86/</id>
    <published>2021-05-28T09:35:13.000Z</published>
    <updated>2021-06-30T10:59:27.129Z</updated>
    
    <content type="html"><![CDATA[<p>在Spring Boot集成Dubbo时，服务发布主要有以下几个步骤：</p><ul><li>添加dubbo-spring-boot-starter依赖</li><li>定义@org.apache.dubbo.config.annotation.Service注解</li></ul><p>声明@DubboComponentScan，用于扫描@Service注解，Dubbo中的@Service注解和Spring中提供的@Service注解功能类似，用于实现Dubbo服务的暴露，与它相对应的时@Reference，它的作用类似于Spring中的@Autowired注解。而@DubboComponentScan和Spring中的@ComponentScan作用类似，用于扫描@Service、@Reference等注解。</p><h3 id="DubboComponentScan注解解析"><a href="#DubboComponentScan注解解析" class="headerlink" title="@DubboComponentScan注解解析"></a>@DubboComponentScan注解解析</h3><p><strong>DubboComponentScan</strong>注解的定义如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Target(ElementType.TYPE)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Import(DubboComponentScanRegistrar.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> DubboComponentScan &#123;</span><br><span class="line">String[] value() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">String[] basePackages() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">Class&lt;?&gt;[] basePackageClasses() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个注解主要通过@Import导入一个DubboComponentScanRegistrar类。DubboComponentScanRegistrar实现了ImportBeanDefinitionRegistrar接口，并且重写了registerBeanDefinitions方法。在registerBeanDefinitions方法中主要做了以下几件事：</p><ul><li>获取扫描包的路径，默认扫描当前配置类所在的包</li><li>注册@Service注解的解析类</li><li>注册@Reference注解的解析类</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DubboComponentScanRegistrar</span> <span class="keyword">implements</span> <span class="title">ImportBeanDefinitionRegistrar</span> </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">refisterBeanDefinitions</span><span class="params">(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata);</span><br><span class="line">registerServiceAnnotationBeanPostProcessor(packagesToScan, registry);</span><br><span class="line">registerReferenceAnnotationBeanPostProcessor(registry);</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ImportBeanDefinitionRegistrar是Spring提供的一种动态注入Bean的机制，和ImportSelector接口的功能类似，在refisterBeanDefinitions方法中，主要会实例化一些BeanDefinition并且注入到Spring IoC容器中；继续看registerServiceAnnotationBeanPostProcessor()方法，逻辑比较简单，就是把SerficeAnnotationBeanPostProcessor注册到容器；registerReferenceAnnotationBeanPostProcessor()方法是把ReferenceAnnotationBeanPostProcessor注册到容器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerServiceAnnotationBeanPostProcessor</span><span class="params">(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 构建BeanDefinitionBuilder</span></span><br><span class="line">        BeanDefinitionBuilder builder = BeanDefinitionBuilder.rootBeanDefinition(ServiceAnnotationBeanPostProcessor.class);</span><br><span class="line">        builder.addConstructorArgValue(packagesToScan);</span><br><span class="line">        builder.setRole(<span class="number">2</span>);</span><br><span class="line">        AbstractBeanDefinition beanDefinition = builder.getBeanDefinition();</span><br><span class="line">        <span class="comment">// 把BeanDefinition注册到IoC容器中</span></span><br><span class="line">        BeanDefinitionReaderUtils.registerWithGeneratedName(beanDefinition, registry);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="Service解析"><a href="#Service解析" class="headerlink" title="@Service解析"></a>@Service解析</h3><p>ServiceAnnotationBeanPostProcessor用于解析@Service注解，ReferenceAnnotationBeanPostProcessor用于解析@Reference注解</p><h3 id="ServiceAnnotationBeanPostProcessor"><a href="#ServiceAnnotationBeanPostProcessor" class="headerlink" title="ServiceAnnotationBeanPostProcessor"></a>ServiceAnnotationBeanPostProcessor</h3><p>ServiceAnnotationBeanPostProcessor类的定义如下，它的核心逻辑就是解析@Service注解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceAnnotationBeanPostProcessor</span> <span class="keyword">implements</span> <span class="title">BeanDefinitionRegistryPostProcessor</span>, <span class="title">EnvironmentAware</span>, <span class="title">ResourceLoaderAware</span>, <span class="title">BeanClassLoaderAware</span> </span>&#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ServiceAnnotationBeanPostProcessor实现了4个接口，EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware这三个接口比较好理解，重点看一下BeanDefinitionRegistryPostProcessor；BeanDefinitionRegistryPostProcessor接口继承自BeanFactoryPostProcessor，是一种比较特殊的BeanFactoryPostProcessor；BeanDefinitionRegistryPostProcessor中的postProcessBeanDefinitionRegistry方法可以让我们实现自定义的注册Bean定义的逻辑。该方法主要做了以下几件事：</p><ul><li>调用registerBeans注册DubboBootstrapApplicationListener类</li><li>通过resolvePackagesToScan对packagesToScan参数进行去空格处理，并把配置文件中配置的扫描参数也一起处理。</li><li>调用registerServiceBeans完成Bean的注册。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessBeanDefinitionRegistry</span><span class="params">(BeanDefinitionRegistry registry)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        AnnotatedBeanDefinitionRegistryUtils.registerBeans(registry, <span class="keyword">new</span> Class[]&#123;DubboBootstrapApplicationListener.class&#125;);</span><br><span class="line">        Set&lt;String&gt; resolvedPackagesToScan = <span class="keyword">this</span>.resolvePackagesToScan(<span class="keyword">this</span>.packagesToScan);</span><br><span class="line">        <span class="keyword">if</span> (!CollectionUtils.isEmpty(resolvedPackagesToScan)) &#123;</span><br><span class="line">            <span class="keyword">this</span>.registerServiceBeans(resolvedPackagesToScan, registry);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>.logger.isWarnEnabled()) &#123;</span><br><span class="line">            <span class="keyword">this</span>.logger.warn(<span class="string">&quot;packagesToScan is empty , ServiceBean registry will be ignored!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>postProcessBeanDefinitionRegistry()方法的核心逻辑都在registerServiceBeans这个方法中，这个方法会查找需要扫描的指定包里面有@Service注解的类并将其注册成Bean。</p><ul><li>定义DubboClassPathBeanDefinitionScanner扫描对象，扫描指定路径下的类，将符合条件的类装配到IoC容器中。</li><li>BeanNameGenerator是Beans体系中比较重要的一个组件，会通过一定的算法计算出需要装配的Bean的name。</li><li>addIncludeFilter设置Scan的过滤条件，只扫描@Service注解修饰的类。</li><li>遍历指定的包，通过findServiceBeanDefinitionHolders查找@Service注解修饰的类。</li><li>通过registerServiceBean完成Bean的注册。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Registers Beans whose classes was annotated &#123;<span class="doctag">@link</span> Service&#125;</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> packagesToScan The base packages to scan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> registry       &#123;<span class="doctag">@link</span> BeanDefinitionRegistry&#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerServiceBeans</span><span class="params">(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        DubboClassPathBeanDefinitionScanner scanner =</span><br><span class="line">                <span class="keyword">new</span> DubboClassPathBeanDefinitionScanner(registry, environment, resourceLoader);</span><br><span class="line"></span><br><span class="line">        BeanNameGenerator beanNameGenerator = resolveBeanNameGenerator(registry);</span><br><span class="line"></span><br><span class="line">        scanner.setBeanNameGenerator(beanNameGenerator);</span><br><span class="line"></span><br><span class="line">        scanner.addIncludeFilter(<span class="keyword">new</span> AnnotationTypeFilter(Service.class));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (String packageToScan : packagesToScan) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Registers @Service Bean first</span></span><br><span class="line">            scanner.scan(packageToScan);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Finds all BeanDefinitionHolders of @Service whether @ComponentScan scans or not.</span></span><br><span class="line">            Set&lt;BeanDefinitionHolder&gt; beanDefinitionHolders =</span><br><span class="line">                    findServiceBeanDefinitionHolders(scanner, packageToScan, registry, beanNameGenerator);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!CollectionUtils.isEmpty(beanDefinitionHolders)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (BeanDefinitionHolder beanDefinitionHolder : beanDefinitionHolders) &#123;</span><br><span class="line">                    registerServiceBean(beanDefinitionHolder, registry, scanner);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (logger.isInfoEnabled()) &#123;</span><br><span class="line">                    logger.info(beanDefinitionHolders.size() + <span class="string">&quot; annotated Dubbo&#x27;s @Service Components &#123; &quot;</span> +</span><br><span class="line">                            beanDefinitionHolders +</span><br><span class="line">                            <span class="string">&quot; &#125; were scanned under package[&quot;</span> + packageToScan + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">                    logger.warn(<span class="string">&quot;No Spring Bean annotating Dubbo&#x27;s @Service was found under package[&quot;</span></span><br><span class="line">                            + packageToScan + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面的代码主要作用就是通过扫描指定路径下添加了@Service注解的类，通过registerServiceBean来注册ServiceBean，整体来看，Dubbo的注解扫描进行服务发布的过程，实际上就是基于Spring的扩展。</p><p>继续分析registerServiceBean方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerServiceBean</span><span class="params">(BeanDefinitionHolder beanDefinitionHolder, BeanDefinitionRegistry registry,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  DubboClassPathBeanDefinitionScanner scanner)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">     Class&lt;?&gt; beanClass = resolveClass(beanDefinitionHolder);</span><br><span class="line"></span><br><span class="line">     Service service = findAnnotation(beanClass, Service.class);</span><br><span class="line"></span><br><span class="line">     Class&lt;?&gt; interfaceClass = resolveServiceInterfaceClass(beanClass, service);</span><br><span class="line"></span><br><span class="line">     String annotatedServiceBeanName = beanDefinitionHolder.getBeanName();</span><br><span class="line"></span><br><span class="line">     AbstractBeanDefinition serviceBeanDefinition =</span><br><span class="line">             buildServiceBeanDefinition(service, interfaceClass, annotatedServiceBeanName);</span><br><span class="line"></span><br><span class="line">     <span class="comment">// ServiceBean Bean name</span></span><br><span class="line">     String beanName = generateServiceBeanName(service, interfaceClass, annotatedServiceBeanName);</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> (scanner.checkCandidate(beanName, serviceBeanDefinition)) &#123; <span class="comment">// check duplicated candidate bean</span></span><br><span class="line">         registry.registerBeanDefinition(beanName, serviceBeanDefinition);</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (logger.isInfoEnabled()) &#123;</span><br><span class="line">             logger.info(<span class="string">&quot;The BeanDefinition[&quot;</span> + serviceBeanDefinition +</span><br><span class="line">                     <span class="string">&quot;] of ServiceBean has been registered with name : &quot;</span> + beanName);</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">             logger.warn(<span class="string">&quot;The Duplicated BeanDefinition[&quot;</span> + serviceBeanDefinition +</span><br><span class="line">                     <span class="string">&quot;] of ServiceBean[ bean name : &quot;</span> + beanName +</span><br><span class="line">                     <span class="string">&quot;] was be found , Did @DubboComponentScan scan to same package in many times?&quot;</span>);</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>resolveClass获取BeanDefinitionHolder中的Bean</li><li>findServiceAnnotation方法从beanClass类中找到@Service注解</li><li>getAnnotationAttributes方法获得注解中的属性，比如loadBalance、cluster等。</li><li>resolveServiceInterfaceClass方法用于获得beanClass对应的接口定义，其实在@Service(interfaceClass=xxxx.class)注解的声明中也可以声明interfaceClass，注解中声明的优先级最高，如果没有声明该属性，则会从父类中查找。</li><li>annotatedServiceBeanName代表Bean的名称。</li><li>buildServiceBeanDefinition用来构造org.apache.dubbo.config.spring.ServiceBean对象，每个Dubbo服务的发布最终都会出现一个ServiceBean。</li><li>调用registerBeanDefinition将ServiceBean注入Spring IoC容器中。</li></ul><p>从整个方法的分析来看，registerServiceBean方法主要是把一个ServiceBean注入到Spring IoC容器中，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceImpl</span> <span class="keyword">implements</span> <span class="title">IHelloService</span> </span>&#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它并不是像普通的Bean注入一样直接将HelloServiceImpl对象的实例注入容器，而是注入一个ServiceBean对象。对于HelloServiceImpl来说，它并不需要把自己注入Spring IoC容器中，而是需要把自己发布到网络上，提供给网络上的服务消费者来访问。那它是怎么发布到网络上的呢？</p><p>上面在postProcessBeanDefinitionRegistry方法中注册了DubboBootstrapApplicationListener事件监听Bean。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DubboBootstrapApplicationListener</span> <span class="keyword">extends</span> <span class="title">OneTimeExecutionApplicationContextEventListener</span> <span class="keyword">implements</span> <span class="title">Ordered</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DubboBootstrap dubboBootstrap = DubboBootstrap.getInstance();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DubboBootstrapApplicationListener</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationContextEvent</span><span class="params">(ApplicationContextEvent event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (event <span class="keyword">instanceof</span> ContextRefreshedEvent) &#123;</span><br><span class="line">            <span class="keyword">this</span>.onContextRefreshedEvent((ContextRefreshedEvent)event);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (event <span class="keyword">instanceof</span> ContextClosedEvent) &#123;</span><br><span class="line">            <span class="keyword">this</span>.onContextClosedEvent((ContextClosedEvent)event);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">onContextRefreshedEvent</span><span class="params">(ContextRefreshedEvent event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dubboBootstrap.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">onContextClosedEvent</span><span class="params">(ContextClosedEvent event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dubboBootstrap.stop();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2147483647</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当所有的Bean都处理完成之后，Spring IoC会发布一个事件，事件类型为ComtextRefreshedEvent，当触发整个事件时，会调用onContextRefreshedEvent方法。在这个方法中，可以看到Dubbo服务启动的触发机制dubboBootstrap.start()。从这个方法中会进入org.apache.dubbo.config.ServiceConfig类中的export()方法，这个方法会启动一个网络监听，从而实现服务发布。</p><blockquote><p>引用</p><p><a href="https://blog.csdn.net/yangbaggio/article/details/105913431">https://blog.csdn.net/yangbaggio/article/details/105913431</a></p><p><a href="https://blog.csdn.net/DaySurprise/article/details/114897735">https://blog.csdn.net/DaySurprise/article/details/114897735</a></p><p><a href="https://www.cnblogs.com/jackion5/p/11219707.html">https://www.cnblogs.com/jackion5/p/11219707.html</a></p></blockquote>]]></content>
    
    
    <summary type="html">使用Dubbo最方便的地方在于它可以和Spring非常方便的集成，实际上，Dubbo对于配置的优化，也是随着Spring一同发展的，从最早的XML形式到后来的注解方式以及自动装配，都是在不断地简化开发过程来提高开发效率。在Spring Boot集成Dubbo时，服务发布主要有以下几个步骤：添加dubbo-spring-boot-starter依赖;定义@org.apache.dubbo.config.annotation.Service注解</summary>
    
    
    
    <category term="Dubbo" scheme="https://gaoxing27.gitee.io/categories/Dubbo/"/>
    
    
    <category term="Spring" scheme="https://gaoxing27.gitee.io/tags/Spring/"/>
    
    <category term="Springboot" scheme="https://gaoxing27.gitee.io/tags/Springboot/"/>
    
    <category term="Dubbo" scheme="https://gaoxing27.gitee.io/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo-原理</title>
    <link href="https://gaoxing27.gitee.io/2021/05/27/dubbo-%E5%8E%9F%E7%90%86/"/>
    <id>https://gaoxing27.gitee.io/2021/05/27/dubbo-%E5%8E%9F%E7%90%86/</id>
    <published>2021-05-27T11:22:17.000Z</published>
    <updated>2021-06-30T10:59:22.503Z</updated>
    
    <content type="html"><![CDATA[<h2 id="dubbo基础"><a href="#dubbo基础" class="headerlink" title="dubbo基础"></a>dubbo基础</h2><p>Dubbo 是一款高性能、轻量级的开源 RPC 框架，提供服务自动注册、自动发现等高效服务治理方案， 可以和 Spring 框架无缝集成。</p><p>随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系(SOA)，也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架。就这样为分布式系统的服务治理框架Dubbo就出现了</p><h4 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h4><p>RPC（Remote Procedure Call Protocol）远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。简言之，RPC使得程序能够像访问本地系统资源一样，去访问远端系统资源。比较关键的一些方面包括：通讯协议、序列化、资源（接口）描述、服务框架、性能、语言支持等。</p><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a><strong>使用场景</strong></h4><ul><li>透明化的远程方法调用：就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。</li><li>软负载均衡及容错机制：可在内网替代 F5 等硬件负载均衡器，降低成本，减少单点。</li><li>服务自动注册与发现：不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。</li></ul><h4 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a><strong>核心功能</strong></h4><ul><li>Remoting：网络通信框架，提供对多种NIO框架抽象封装，包括“同步转异步”和“请求-响应”模式的信息交换方式。</li><li>Cluster：服务框架，提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li><li>Registry：服务注册，基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li></ul><h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a><strong>核心组件</strong></h4><ul><li><p>Provider：暴露服务的服务提供方</p></li><li><p>Consumer：调用远程服务消费方</p></li><li><p>Registry：服务注册与发现注册中心</p></li><li><p>Monitor：监控中心和访问调用统计</p></li><li><p>Container：服务运行容器</p><p><strong>注册中心</strong></p><p>Zookeeper 注册中心：基于分布式协调系统 Zookeeper 实现，采用 Zookeeper 的 watch 机制实现数据变更。</p></li></ul><p><img src="/images/dubbo/Dubbo%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6.png" alt="Dubbo核心组件"></p><h4 id="服务注册与发现流程"><a href="#服务注册与发现流程" class="headerlink" title="服务注册与发现流程"></a><strong>服务注册与发现流程</strong></h4><ul><li>服务容器Container负责启动，加载，运行服务提供者。</li><li>服务提供者Provider在启动时，向注册中心注册自己提供的服务。</li><li>服务消费者Consumer在启动时，向注册中心订阅自己所需的服务。</li><li>注册中心Registry返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者Consumer，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li><li>服务消费者Consumer和提供者Provider，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心Monitor。</li></ul><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p>Dubbo框架设计一共划分了10个层，而最上面的Service层是留给实际想要使用Dubbo开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口， 位于中轴线上的为双方都用到的接口。</p><ul><li>接口服务层（Service）：该层与业务逻辑相关，根据 provider 和 consumer 的业务设计对应的接口和实现</li><li>配置层（Config）：对外配置接口，以 ServiceConfig 和 ReferenceConfig 为中心</li><li>服务代理层（Proxy）：服务接口透明代理，生成服务的客户端 Stub 和 服务端的 Skeleton，以 ServiceProxy 为中心，扩展接口为 ProxyFactory</li><li>服务注册层（Registry）：封装服务地址的注册和发现，以服务 URL 为中心，扩展接口为 RegistryFactory、Registry、RegistryService</li><li>路由层（Cluster）：封装多个提供者的路由和负载均衡，并桥接注册中心，以Invoker 为中心，扩展接口为 Cluster、Directory、Router 和 LoadBlancce</li><li>监控层（Monitor）：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory、Monitor 和 MonitorService</li><li>远程调用层（Protocal）：封装 RPC 调用，以 Invocation 和 Result 为中心，扩展接口为 Protocal、Invoker 和 Exporter</li><li>信息交换层（Exchange）：封装请求响应模式，同步转异步。以 Request 和Response 为中心，扩展接口为 Exchanger、ExchangeChannel、ExchangeClient 和 ExchangeServer</li><li>网络 传输 层（Transport）：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel、Transporter、Client、Server 和 Codec</li><li>数据序列化层（Serialize）：可复用的一些工具，扩展接口为 Serialization、ObjectInput、ObjectOutput 和 ThreadPool</li></ul><p><img src="/images/dubbo/Dubbo%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%9B%BE.png" alt="dubbo架构设计图"></p><h3 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h3><h4 id="服务暴露过程"><a href="#服务暴露过程" class="headerlink" title="服务暴露过程"></a>服务暴露过程</h4><p><img src="/images/dubbo/dubbo%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2%E5%92%8C%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B.png" alt="dubbo服务暴露和调用过程.png"></p><p>服务器端（服务提供者） 在框架启动时， 会初始化服务实例， 通过Proxy组件调<br>用具体协议（Protocol ） ,把服务端要暴露的接口封装成Invoker （真实类型是<br>AbstractProxylnvoker）,然后转换成Exporter,这个时候框架会打开服务端口等并记录服务实例<br>到内存中， 最后通过Registry把服务元数据注册到注册中心和本地。   </p><p>Proxy组件： Dubbo框架生成的代理类， 调用的方法其实是Proxy组件生成的代理方法， 会自动发起远程/本地调用， 并返回结果,<br>整个过程对用户完全透明。</p><p> Protocol： 协议就是对数据格式的一种约定。 它可以把我们对接口的配置,<br>根据不同的协议转换成不同的Invoker对象。 例如： 用DubboProtocol可以把XML文<br>件中一个远程接口的配置转换成一个Dubbolnvoker</p><p>Exporter： 用于暴露到注册中心的对象， 它的内部属性持有了 Invoker对象， 我们可以<br>认为它在Invoker上包了 一层。</p><p>Registry： 把Exporter注册到注册中心  </p><h4 id="服务调用过程"><a href="#服务调用过程" class="headerlink" title="服务调用过程"></a>服务调用过程</h4><p><img src="/images/dubbo/dubbo%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2%E5%92%8C%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B.png" alt="dubbo服务暴露和调用过程.png"></p><p>调用过程也是从一个Proxy开始的， Proxy持有了一个Invoker对象。 然后触发invoke<br>调用。 在invoke调用过程中， 需要使用Cluster, Cluster负责容错， 如调用失败的重试。 Cluster<br>在调用之前会通过Directory获取所有可以调用的远程服务Invoker列表（一个接口可能有多个<br>节点提供服务） 。 由于可以调用的远程服务有很多， 此时如果用户配置了路由规则（如指定某些<br>方法只能调用某个节点） ， 那么还会根据路由规则将Invoker列表过滤一遍。<br>然后， 存活下来的Invoker可能还会有很多，于是会继续通过<br>LoadBalance方法做负载均衡， 最终选出一个可以调用的Invokero这个Invoker在调用之前又会<br>经过一个过滤器链， 这个过滤器链通常是处理上下文、 限流、 计数等。<br>接着， 会使用Client做数据传输， 如我们常见的Netty Client等。 传输之前肯定要做一些私<br>有协议的构造， 此时就会用到Codec接口。 构造完成后， 就对数据包做序列化（Serialization）,<br>然后传输到服务提供者端。 服务提供者收到数据包， 也会使用Codec处理协议头及一些半包、<br>粘包等。 处理完成后再对完整的数据报文做反序列化处理。<br>随后， 这个Request会被分配到线程池（ThreadPool）中进行处理。Server会处理这些Request,<br>根据请求查找对应的Exporter （它内部持有了 Invoker）。 Invoker是被用装饰器模式一层一层套<br>了非常多Filter的， 因此在调用最终的实现类之前， 又会经过一个服务提供者端的过滤器链。<br>最终， 我们得到了具体接口的真实实现并调用， 再原路把结果返回。<br>至此， 一个完整的远程调用过程就结束了。 </p><h4 id="SPI机制"><a href="#SPI机制" class="headerlink" title="SPI机制"></a>SPI机制</h4><p>SPI，Service Provider Interface，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，mysql和postgresql都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。</p><p>当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader</p><p> Dubbo 并未使用Java SPI，而是重新实现了一套功能更强的SPI机制。Dubbo SPI的相关逻辑被封装在了ExtensionLoader类中，通过ExtensionLoader，我们可以加载指定的实现类。Dubbo SPI所需的配置文件，需放置在META-INF/dubbo路径下</p><p>与Java SPI实现类配置不同，Dubbo SPI是通过键值对的方式进行配置。这样我们可以按需加载指定的实现类。另外在测试Dubbo SPI时，需要在Robot接口上标注@SPI注解 </p><h4 id="monitor原理"><a href="#monitor原理" class="headerlink" title="monitor原理"></a>monitor原理</h4><ul><li>Consumer 端在发起调用之前会先走 filter 链；provider 端在接收到请求时也是先走 filter 链，然后才进行真正的业务逻辑处理。默认情况下，在 consumer 和 provider 的 filter 链中都会有 Monitorfilter。</li></ul><ol><li>MonitorFilter 向 DubboMonitor 发送数据</li><li>DubboMonitor 将数据进行聚合后（默认聚合 1min 中的统计数据）暂存到ConcurrentMap&lt;Statistics, AtomicReference&gt; statisticsMap，然后使用一个含有 3 个线程（线程名字：DubboMonitorSendTimer）的线程池每隔 1min 钟，调用 SimpleMonitorService 遍历发送 statisticsMap 中的统计数据，每发送完毕一个，就重置当前的 Statistics 的 AtomicReference</li><li>SimpleMonitorService 将这些聚合数据塞入 BlockingQueue queue 中（队列大写为 100000）</li><li>SimpleMonitorService 使用一个后台线程（线程名为：DubboMonitorAsyncWriteLogThread）将 queue 中的数据写入文件（该线程以死循环的形式来写）</li><li>SimpleMonitorService 还会使用一个含有 1 个线程（线程名字：DubboMonitorTimer）的线程池每隔 5min 钟，将文件中的统计数据画成图表</li></ol><h4 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h4><p>默认：Random LoadBalance:</p><ul><li>Random LoadBalance: 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀。</li><li>RoundRobin LoadBalance: 轮循选取提供者策略，平均分布，但是存在请求累积的问题。</li><li>LeastActive LoadBalance: 最少活跃调用策略，解决慢提供者接收更少的请求。</li><li>ConstantHash LoadBalance: 一致性 Hash 策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动。</li></ul><h4 id="集群容错机制"><a href="#集群容错机制" class="headerlink" title="集群容错机制"></a>集群容错机制</h4><p>默认：Failover Cluster</p><ul><li>Failover </li></ul><p>当出现失败时， 会重试其他服务器。 用户可以通过retries=”2n设置重试次数。 这是<br>Dubbo的默认容错机制， 会对请求做负载均衡。 通常使用在读操作或幕等的写操作上，<br>但重试会导致接口的延退增大， 在下游机器负载已经达到极限时， 重试容易加重下游<br>服务的负载</p><ul><li>Failfast</li></ul><p> 快速失败， 当请求失败后， 快速返回异常结果， 不做任何重试。 该容错机制会对请求<br>做负载均衡， 通常使用在非幕等接口的调用上。 该机制受网络抖动的影响较大</p><ul><li>Failsafe</li></ul><p> 当出现异常时， 直接忽略异常。 会对请求做负载均衡。 通常使用在“佛系” 调用场景，<br>即不关心调用是否成功， 并且不想抛异常影响外层调用， 如某些不重要的日志同步， 即使出现异常也无所谓</p><ul><li>Fallback</li></ul><p> 请求失败后， 会自动记录在失败队列中， 并由一个定时线程池定时重试， 适用于一些<br>异步或最终一致性的请求。 请求会做负载均衡</p><ul><li>Forking</li></ul><p> 同时调用多个相同的服务， 只要其中一个返回， 则立即返回结果。 用户可以配置forks=“最大并行调用数” 参数来确定最大并行调用的服务数量。 通常使用在对接口<br>实时性要求极高的调用上， 但也会浪费更多的资源</p><ul><li>Broadcast </li></ul><p>广播调用所有可用的服务， 任意一个节点报错则报错。 由于是广播， 因此请求不需要<br>做负载均衡。 通常用于服务状态更新后的广播</p><ul><li>Mock</li></ul><p> 提供调用失败时， 返回伪造的响应结果。 或直接强制返回伪造的结果， 不会发起远程<br>调用</p><ul><li>Available </li></ul><p>最简单的方式， 请求不会做负载均衡， 遍历所有服务列表， 找到第一个可用的节点，<br>直接请求并返回结果。 如果没有可用的节点， 则直接抛出异常</p><ul><li>Mergeable </li></ul><p>Mergeable可以自动把多个节点请求得到的结果进行合并</p><h4 id="调用超时设置"><a href="#调用超时设置" class="headerlink" title="调用超时设置"></a>调用超时设置</h4><p>dubbo 在调用服务不成功时，默认是会重试两次。</p><ul><li>服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。</li><li>服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。</li></ul><h4 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h4><p>Dubbo注册中心集群挂掉之后，消费者和生产者之间可以继续通信；因为在Dubbo启动时，消费者会从注册中心Zookeeper拉取注册的生产者的地址接口等数据，缓存在本地，每次调用时，按照本地缓存的地址调用就可以。</p><p>默认使用 Netty 作为通讯框架。</p><p>支持的通信协议：</p><ul><li>Dubbo： 单一长连接和 NIO 异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议 TCP，异步 Hessian 序列化。Dubbo推荐使用dubbo协议。</li><li>RMI： 采用 JDK 标准的 RMI 协议实现，传输参数和返回参数对象需要实现 Serializable 接口，使用 Java 标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议 TCP。 多个短连接 TCP 协议传输，同步传输，适用常规的远程服务调用和 RMI 互操作。在依赖低版本的 Common-Collections 包，Java 序列化存在安全漏洞。</li><li>WebService：基于 WebService 的远程调用协议，集成 CXF 实现，提供和原生 WebService 的互操作。多个短连接，基于 HTTP 传输，同步传输，适用系统集成和跨语言调用。</li><li>HTTP： 基于 Http 表单提交的远程调用协议，使用 Spring 的 HttpInvoke 实现。多个短连接，传输协议 HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器 JS 调用。</li><li>Hessian：集成 Hessian 服务，基于 HTTP 通讯，采用 Servlet 暴露服务，Dubbo 内嵌 Jetty 作为服务器时默认实现，提供与 Hession 服务互操作。多个短连接，同步 HTTP 传输，Hessian 序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件。</li><li>Memcache：基于 Memcache实现的 RPC 协议。</li><li>Redis：基于 Redis 实现的RPC协议。</li></ul><h4 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h4><p>为保证在远程调用过程中对象的完整性和可传递性，服务消费者和服务提供者之间传递数据的时候需要进行序列化和反序列化，默认使用 Hessian 序列化，还有 Duddo、FastJson、Java 自带序列化。</p><p>序列化：把对象转换成有序的二进制字节流，以便在网络上传输或者保存在本地文件中</p><p>反序列化：把序列化后的对象的二进制字节流通过反序列化重建对象。</p><h4 id="安全防护"><a href="#安全防护" class="headerlink" title="安全防护"></a>安全防护</h4><ul><li>Dubbo 通过 Token 令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。</li><li>Dubbo 还提供服务黑白名单，来控制服务所允许的调用方。</li></ul><h3 id="用到的设计模式"><a href="#用到的设计模式" class="headerlink" title="用到的设计模式"></a>用到的设计模式</h3><ul><li><p>工厂模式</p></li><li><p>装饰器模式</p></li><li><p>观察者模式</p></li><li><p>动态代理模式</p></li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h4 id="版本兼容性问题"><a href="#版本兼容性问题" class="headerlink" title="版本兼容性问题"></a>版本兼容性问题</h4><p>可以用版本号（version）解决兼容性问题，多个不同版本的服务注册到注册中心，版本号不同的服务相互间不引用</p><h4 id="与SpringCloud关系"><a href="#与SpringCloud关系" class="headerlink" title="与SpringCloud关系"></a>与SpringCloud关系</h4><p>Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 Spring Cloud 诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spring、Spring Boot 的优势之上，两个框架在开始目标就不一致，Dubbo 定位服务治理、Spring Cloud 是打造一个生态。</p><h4 id="与SpringCloud区别"><a href="#与SpringCloud区别" class="headerlink" title="与SpringCloud区别"></a>与SpringCloud区别</h4><ul><li><p>Dubbo 底层是使用 Netty 这样的 NIO 框架，是基于 TCP 协议传输的，配合以 Hession 序列化完成 RPC 通信。</p></li><li><p>Spring Cloud 是基于 Http 协议 Rest 接口调用远程过程的通信，相对来说 Http 请求会有更大的报文，占的带宽也会更多。但是 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。</p></li></ul><h4 id="与Dubbox的区别"><a href="#与Dubbox的区别" class="headerlink" title="与Dubbox的区别"></a>与Dubbox的区别</h4><ul><li>Dubbox 是继 Dubbo 停止维护后，当当网基于 Dubbo 做的一个扩展项目，如加了服务可 Restful 调用，更新了开源组件等。</li></ul><blockquote><p>引用<br><a href="https://juejin.cn/post/6844904127076499463">https://juejin.cn/post/6844904127076499463</a><br><a href="https://mp.weixin.qq.com/s/FPbu8rFOHyTGROIV8XJeTA">https://mp.weixin.qq.com/s/FPbu8rFOHyTGROIV8XJeTA</a></p></blockquote>]]></content>
    
    
    <summary type="html">Dubbo 是一款高性能、轻量级的开源 RPC 框架，提供服务自动注册、自动发现等高效服务治理方案， 可以和 Spring 框架无缝集成。随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系(SOA)，也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架。就这样为分布式系统的服务治理框架Dubbo就出现了</summary>
    
    
    
    <category term="Dubbo" scheme="https://gaoxing27.gitee.io/categories/Dubbo/"/>
    
    
    <category term="Spring" scheme="https://gaoxing27.gitee.io/tags/Spring/"/>
    
    <category term="Dubbo" scheme="https://gaoxing27.gitee.io/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>redis-线程模型</title>
    <link href="https://gaoxing27.gitee.io/2021/05/27/redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <id>https://gaoxing27.gitee.io/2021/05/27/redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-05-27T09:27:14.000Z</published>
    <updated>2021-06-30T10:41:43.697Z</updated>
    
    <content type="html"><![CDATA[<p> redis是单线程模型，所谓单线程指的是网络请求模块使用了一个线程，即一个线程处理所有网络请求，其他模块该使用多线程仍会使用了多个线程。redis是基于内存的，那么<code>CPU</code>不是<code>Redis</code>的瓶颈。<code>Redis</code>的瓶颈最有可能是机器内存或者网络带宽。</p><p><code>Redis</code>基于<code>Reactor</code>模式开发了自己的网络事件处理器，称之为文件事件处理器(<code>File Event Hanlder</code>)。文件事件处理器由<code>Socket</code>、<code>IO</code>多路复用程序、文件事件分派器(<code>dispather</code>)，事件处理器(<code>handler</code>)四部分组成。文件事件处理器的模型如下所示：</p><p><img src="/images/redis/redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%9B%BE.png" alt="redis线程模型图"></p><h3 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h3><p><code>IO</code>多路复用程序会同时监听多个<code>socket</code>，当被监听的<code>socket</code>准备好执行<code>accept</code>、<code>read</code>、<code>write</code>、<code>close</code>等操作时，与这些操作相对应的文件事件就会产生。<code>IO</code>多路复用程序会把所有产生事件的<code>socket</code>压入一个队列中，然后有序地每次仅一个<code>socket</code>的方式传送给文件事件分派器，文件事件分派器接收到<code>socket</code>之后会根据<code>socket</code>产生的事件类型调用对应的事件处理器进行处理。</p><h3 id="事件种类"><a href="#事件种类" class="headerlink" title="事件种类"></a>事件种类</h3><ul><li><p>AE_READABLE</p><p>当客户端连接服务器端时，服务器端会将连接应答处理器与<code>socket</code>的<code>AE_READABLE</code>事件关联起来；</p><p>当客户端向服务端发送命令的时候，服务器端将命令请求处理器与<code>AE_READABLE</code>事件关联起来；</p></li><li><p>AE_WRITABLE</p><p>当服务端有数据需要回传给客户端时，服务端将命令回复处理器与<code>socket</code>的<code>AE_WRITABLE</code>事件关联起来。</p></li></ul><h3 id="文件事件处理器"><a href="#文件事件处理器" class="headerlink" title="文件事件处理器"></a>文件事件处理器</h3><ul><li><strong>连接应答处理器</strong>：用于处理客户端的连接请求；</li><li><strong>命令请求处理器</strong>：用于执行客户端传递过来的命令；</li><li><strong>命令回复处理器</strong>：用于返回客户端命令的执行结果；</li></ul><h3 id="客户端与服务端交互"><a href="#客户端与服务端交互" class="headerlink" title="客户端与服务端交互"></a>客户端与服务端交互</h3><p><img src="/images/redis/redis%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8B.png" alt="redis客户端与服务端交互流程"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>I/O多路复用本来就是用来解决对多个I/O监听时，一个I/O阻塞影响其他I/O的问题</p><blockquote><p>引用<br><a href="https://juejin.cn/post/6844903849489235982">https://juejin.cn/post/6844903849489235982</a></p></blockquote>]]></content>
    
    
    <summary type="html">redis是单线程模型，更严谨一点，Redis的单线程指的是网络请求模块使用了一个线程，即一个线程处理所有网络请求，其他模块该使用多线程，仍会使用了多个线程。redis是基于内存的，那么`CPU`不是`Redis`的瓶颈。`Redis`的瓶颈最有可能是机器内存或者网络带宽。</summary>
    
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/categories/redis/"/>
    
    
    <category term="IO" scheme="https://gaoxing27.gitee.io/tags/IO/"/>
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/tags/redis/"/>
    
    <category term="线程模型" scheme="https://gaoxing27.gitee.io/tags/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>redis-集群</title>
    <link href="https://gaoxing27.gitee.io/2021/05/26/redis-%E9%9B%86%E7%BE%A4/"/>
    <id>https://gaoxing27.gitee.io/2021/05/26/redis-%E9%9B%86%E7%BE%A4/</id>
    <published>2021-05-26T09:41:51.000Z</published>
    <updated>2021-06-30T10:41:35.889Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><p>Redis Cluster是Redis官方提供的Redis集群功能，分布式架构，去中心化，即Redis Cluster中有多个节点，每个节点都负责进行数据读写操作，每个节点之间通过一种特殊的二进制 协议相互交互集群信息进行通信。Redis Cluster 将所有数据划分为 16384 的 slots，，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中， 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信 息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。  另外，RedisCluster 的每个节点会将集群的配置信息持久化到配置文件中，所以 必须确保配置文件是可写的，而且尽量不要依靠人工修改配置文件。</p><p><img src="/images/redis/redis-cluster-%E6%9E%B6%E6%9E%84.png" alt="redis-cluster-架构"></p><p>跳转：当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并 不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点 地址，告诉客户端去连这个节点去获取数据。客户端收到 MOVED 指令后，要立即纠正本地的槽位映射表。后续所有 key 将 使用新的槽位映射表。</p><p>容错：Redis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会 自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发 生故障时，集群将完全处于不可用状态。不过 Redis 也提供了一个参数 cluster-require-full-coverage 可以允许部分节点故障，其它节点还可以继续 提供对外访问。</p><h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p><img src="/images/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png" alt="哨兵模式"></p><p>More Actions我们可以将 Redis Sentinel 集群看成是一个 ZooKeeper 集群，它是集群高可用 的心脏，它一般是由 3～5 个节点组成，这样挂了个别节点集群还可以正常运转。 它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点 切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来 查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时， 客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户 端。如此应用程序将无需重启即可自动完成节点切换。比如上图的主节点挂掉 后，集群将可能自动调整为下图所示结构。</p><p><img src="/images/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE%E5%90%8E.png" alt="哨兵模式重新选举后"></p><p>从这张图中我们能看到主节点挂掉了，原先的主从复制也断开了，客户端和损坏 的主节点也断开了。从节点被提升为新的主节点，其它从节点开始和新的主节点 建立复制关系。客户端通过新的主节点继续进行交互。Sentinel 会持续监控已经 挂掉了主节点，待它恢复后，原主节点成为新的主节点的从节点；</p><blockquote><p>引用：<br><a href="https://www.jianshu.com/p/813a79ddf932">https://www.jianshu.com/p/813a79ddf932</a><br>《Redis 深度历险：核心原理与应用实践》</p></blockquote>]]></content>
    
    
    <summary type="html">Redis Cluster是Redis官方提供的Redis集群功能，分布式架构，去中心化，即Redis Cluster中有多个节点，每个节点都负责进行数据读写操作，每个节点之间通过一种特殊的二进制 协议相互交互集群信息进行通信。Redis Cluster 将所有数据划分为 16384 的 slots，，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中， 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信 息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。</summary>
    
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/categories/redis/"/>
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-基础理论</title>
    <link href="https://gaoxing27.gitee.io/2021/05/25/redis-%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/"/>
    <id>https://gaoxing27.gitee.io/2021/05/25/redis-%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/</id>
    <published>2021-05-25T09:43:01.000Z</published>
    <updated>2021-06-30T10:41:21.496Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。</li></ul><ul><li>支持数据持久化，支持AOF和RDB两种持久化方式。</li></ul><ul><li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。</li></ul><ul><li>数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。</li></ul><ul><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</li></ul><ul><li>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</li></ul><ul><li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</li></ul><ul><li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</li></ul><h4 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a><strong>Redis为什么这么快</strong></h4><ol><li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；</li><li>数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；</li><li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li><li>使用多路 I/O 复用模型，非阻塞 IO；</li><li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li></ol><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><h4 id="Redis有哪些数据类型"><a href="#Redis有哪些数据类型" class="headerlink" title="Redis有哪些数据类型"></a><strong>Redis有哪些数据类型</strong></h4><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求</p><table><thead><tr><th>数据类型</th><th>可以存储的值</th><th>操作</th><th>应用场景</th></tr></thead><tbody><tr><td>STRING</td><td>字符串、整数或者浮点数</td><td>对整个字符串或者字符串的其中一部分执行操作<br/>对整数和浮点数执行自增或者自减操作</td><td>做简单的键值对缓存</td></tr><tr><td>LIST</td><td>列表</td><td>从两端压入或者弹出元素<br/>对单个或者多个元素进行修剪，<br/>只保留一个范围内的元素</td><td>存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据</td></tr><tr><td>SET</td><td>无序集合</td><td>添加、获取、移除单个元素<br/>检查一个元素是否存在于集合中<br/>计算交集、并集、差集<br/>从集合里面随机获取元素</td><td>交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集</td></tr><tr><td>HASH</td><td>包含键值对的无序散列表</td><td>添加、获取、移除单个键值对<br/>获取所有键值对<br/>检查某个键是否存在</td><td>结构化的数据，比如一个对象</td></tr><tr><td>ZSET</td><td>有序集合</td><td>添加、获取、删除元素<br/>根据分值范围或者成员来获取元素<br/>计算一个键的排名</td><td>去重但可以排序，如获取排名前几名的用户</td></tr></tbody></table><h4 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h4><p><strong>计数器</strong></p><p>可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。</p><p><strong>缓存</strong></p><p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p><p><strong>会话缓存</strong></p><p>可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。</p><p><strong>全页缓存（FPC）</strong></p><p>除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</p><p><strong>查找表</strong></p><p>例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。</p><p><strong>消息队列(发布/订阅功能)</strong></p><p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。</p><p><strong>分布式锁实现</strong></p><p>在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。</p><p><strong>其它</strong></p><p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。</p><h3 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h3><p><strong>详情</strong>：<a href="https://gaoxing27.github.io/2021/05/19/redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/">redis-线程模型</a></p><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。</p><p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:</p><h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>RDB（Redis DataBase）是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。</p><p><strong>优点：</strong></p><p>1、只有一个文件 dump.rdb，方便持久化。</p><p>2、容灾性好，一个文件可以保存到安全的磁盘。</p><p>3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能</p><p>4.相对于数据集大时，比 AOF 的启动效率更高。</p><p><strong>缺点：</strong></p><p>1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)</p><h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件，当重启Redis会重新将持久化的日志中文件恢复数据。当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p><p><strong>优点：</strong></p><p>1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。</p><p>2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。</p><p>3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</p><p><strong>缺点：</strong></p><p>1、AOF 文件比 RDB 文件大，且恢复速度慢。</p><p>2、数据集大的时候，比 rdb 启动效率低。</p><h4 id="持久化方式选择"><a href="#持久化方式选择" class="headerlink" title="持久化方式选择"></a><strong>持久化方式选择</strong></h4><p>一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</p><p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。</p><p>有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。</p><p>如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。</p><h3 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h3><ul><li><p><strong>定时过期：</strong>每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</p></li><li><p><strong>惰性过期</strong>：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</p></li><li><p><strong>定期过期</strong>：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。<br>(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)<br>Redis中同时使用了惰性过期和定期过期两种过期策略。</p></li></ul><h3 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h3><p>Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。MySQL里有2000w数据，redis中只存20w的数据，redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略，淘汰后的数据就是热点数据。</p><p><strong>全局的键空间选择性移除</strong></p><ul><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</li></ul><ul><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）</li></ul><ul><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li></ul><p><strong>设置过期时间的键空间选择性移除</strong></p><ul><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</li></ul><ul><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</li></ul><ul><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li></ul><p>Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。</p><h3 id="线程模型-1"><a href="#线程模型-1" class="headerlink" title="线程模型"></a>线程模型</h3><p><strong><a href="https://gaoxing27.gitee.io/2021/05/19/redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/">传送门</a></strong></p><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务提供了一种将多个命令打包，然后一次性、按顺序地执行的机制，并且事务在执行的期间不会主动中断——服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的其他命令 。</p><p><strong>Redis事务的三个阶段</strong></p><ol><li>事务开始 MULTI</li><li>命令入队</li><li>事务执行 EXEC</li></ol><p>注：如果在一个事务中的命令出现错误，那么所有的命令都不会执行；<br>如果在一个事务运行中出现运行错误，那么正确的命令会被执行 ；在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的安全性。<br>Redis 事务保证了其中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。 </p><h3 id="集群方案"><a href="#集群方案" class="headerlink" title="集群方案"></a>集群方案</h3><p>详情：<a href="https://gaoxing27.github.io/2021/05/19/redis-%E9%9B%86%E7%BE%A4/">redis-集群</a></p><h4 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h4><p>Redis Cluster是Redis官方提供的Redis集群功能，分布式架构，去中心化，即Redis Cluster中有多个节点，每个节点都负责进行数据读写操作，每个节点之间通过一种特殊的二进制协议相互交互集群信息进行通信。Redis Cluster 将所有数据划分为 16384 的 slots，，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中， 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。  另外，RedisCluster 的每个节点会将集群的配置信息持久化到配置文件中，所以必须确保配置文件是可写的，而且尽量不要依靠人工修改配置文件。</p><p><img src="/images/redis/redis-cluster-%E6%9E%B6%E6%9E%84.png" alt="redis-cluster-架构"></p><p>跳转：当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到 MOVED 指令后，要立即纠正本地的槽位映射表。后续所有 key 将 使用新的槽位映射表。</p><p>容错：Redis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发 生故障时，集群将完全处于不可用状态。不过 Redis 也提供了一个参数 cluster-require-full-coverage 可以允许部分节点故障，其它节点还可以继续 提供对外访问。</p><h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><p><img src="/images/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png" alt="哨兵模式"></p><p>可以将 Redis Sentinel集群看成是一个 ZooKeeper 集群，它是集群高可用的心脏，它一般是由 3～5 个节点组成，这样挂了个别节点集群还可以正常运转。 它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点 切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来 查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时， 客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户 端。如此应用程序将无需重启即可自动完成节点切换。比如上图的主节点挂掉 后，集群将可能自动调整为下图所示结构。</p><p><img src="/images/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE%E5%90%8E.png" alt="哨兵模式重新选举后"></p><p>从这张图中我们能看到主节点挂掉了，原先的主从复制也断开了，客户端和损坏 的主节点也断开了。从节点被提升为新的主节点，其它从节点开始和新的主节点 建立复制关系。客户端通过新的主节点继续进行交互。Sentinel 会持续监控已经 挂掉了主节点，待它恢复后，原主节点成为新的主节点的从节点；</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p><strong>详情：<a href="https://gaoxing27.github.io/2021/04/05/redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/">redis-分布式锁</a></strong></p><h3 id="缓存问题"><a href="#缓存问题" class="headerlink" title="缓存问题"></a>缓存问题</h3><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p><p>解决方案</p><p>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。<br>一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。<br>给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。</p><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p><p>解决方案</p><p>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；<br>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击<br>采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力<br>附加</p><p>对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。<br>Bitmap： 典型的就是哈希表<br>缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。</p><p><strong>布隆过滤器（推荐）</strong></p><p>就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。<br>它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。<br>Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。<br>Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。<br>Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。</p><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><p>解决方案</p><p>设置热点数据永远不过期。<br>加互斥锁，互斥锁</p><h4 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h4><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p><p>解决方案</p><p>直接写个缓存刷新页面，上线时手工操作一下；</p><p>数据量不大，可以在项目启动的时候自动进行加载；</p><p>定时刷新缓存；</p><h4 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h4><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</p><p>缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。</p><p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p><p>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p><p>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p><p>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p><p>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p><p>服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。</p><h4 id="热点数据和冷数据"><a href="#热点数据和冷数据" class="headerlink" title="热点数据和冷数据"></a>热点数据和冷数据</h4><p>热点数据，缓存才有价值</p><p>对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存</p><p>对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。</p><p>数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。</p><p>那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。</p><h4 id="缓存热点key"><a href="#缓存热点key" class="headerlink" title="缓存热点key"></a>缓存热点key</h4><p>缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p><p>解决方案</p><p>对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询</p><h4 id="双写不一致"><a href="#双写不一致" class="headerlink" title="双写不一致"></a>双写不一致</h4><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。</p><table><thead><tr><th>问题场景</th><th>描述</th><th>解决</th></tr></thead><tbody><tr><td>先写缓存，再写数据库，缓存写成功，数据库写失败</td><td>缓存写成功，但写数据库失败或者响应延迟，则下次读取（并发读）缓存时，就出现脏读</td><td>这个写缓存的方式，本身就是错误的，需要改为先写数据库，把旧缓存置为失效；读取数据的时候，如果缓存不存在，则读取数据库再写缓存</td></tr><tr><td>先写数据库，再写缓存，数据库写成功，缓存写失败</td><td>写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据</td><td>缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现</td></tr><tr><td>需要缓存异步刷新</td><td>指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补救措施）时候</td><td>确定哪些数据适合此类场景，根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔</td></tr></tbody></table><blockquote><p>引用</p><p><a href="https://blog.csdn.net/ThinkWon/article/details/103522351">https://blog.csdn.net/ThinkWon/article/details/103522351</a><br><a href="https://www.jianshu.com/p/813a79ddf932">https://www.jianshu.com/p/813a79ddf932</a></p><p>《Redis 深度历险：核心原理与应用实践》</p></blockquote>]]></content>
    
    
    <summary type="html">Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案</summary>
    
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/categories/redis/"/>
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-分布式锁</title>
    <link href="https://gaoxing27.gitee.io/2021/05/24/redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>https://gaoxing27.gitee.io/2021/05/24/redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-05-24T14:43:10.000Z</published>
    <updated>2021-06-30T10:41:07.988Z</updated>
    
    <content type="html"><![CDATA[<p>想让同一时刻只有一个线程在执行某段代码，或者说控制资源在同一时刻只能被一个线程持有并操作，这个时候需要锁。以淘宝双11为例，在0点这一刻，如果有几十万甚至上百万的人同时去查看某个商品的详情，这时候会触发商品的查询，如果我们不做控制，全部走到数据库去，那是有可能直接将数据库打垮的。这个时候一个比较常用的做法就是进行加锁，只让1个线程去查询，其他线程待等待这个线程的查询结果后，直接拿结果。在这个例子中，锁用于控制访问数据库的流量，最终起到了保护系统的作用。</p><p>再举个例子，某平台做活动“秒杀茅台”，假如活动只秒杀1瓶，但是同时有10万人在同一时刻去抢，如果底层不做控制，有10000个人抢到了，额外的9999瓶平台就要自己想办法解决了。此时，我们可以在底层通过加锁或者隐式加锁的方式来解决这个问题。此外，锁也经常用来解决并发下的数据安全方面的问题，这里就不一一举例了。</p><p>分布式锁是锁的一种，JVM 锁，如synchronized、Lock，只能作用于单个 JVM，可以简单理解为就是单台服务器（容器），而对于多台服务器之间，JVM 锁则没法解决，这时候就需要引入分布式锁。常见实现分布式锁的方式有：Redis、Zookeeper。</p><h3 id="Redis实现分布式锁"><a href="#Redis实现分布式锁" class="headerlink" title="Redis实现分布式锁"></a>Redis实现分布式锁</h3><h4 id="set命令"><a href="#set命令" class="headerlink" title="set命令"></a>set命令</h4><p>加锁通常使用 set 命令来实现，伪代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set key value PX milliseconds NX</span><br></pre></td></tr></table></figure><p>几个参数的意义如下：</p><p>key、value：键值对</p><p>PX milliseconds：设置键的过期时间为 milliseconds 毫秒。</p><p>NX：只在键不存在时，才对键进行设置操作。SET key value NX 效果等同于 SETNX key value。</p><p>PX、expireTime 参数则是用于解决没有解锁导致的死锁问题。因为如果没有过期时间，万一程序员写的代码有 bug 导致没有解锁操作，则就出现了死锁，因此该参数起到了一个“兜底”的作用。</p><p>NX 参数用于保证在多个线程并发 set 下，只会有1个线程成功，起到了锁的“唯一”性。</p><p>解锁需要两步操作：</p><ol><li>查询当前“锁”是否还是我们持有，因为存在过期时间，所以可能等你想解锁的时候，“锁”已经到期，然后被其他线程获取了，所以我们在解锁前需要先判断自己是否还持有“锁”</li><li>如果“锁”还是我们持有，则执行解锁操作，也就是删除该键值对，并返回成功；否则，直接返回失败。</li></ol><p>由于当前 Redis 还没有原子命令直接支持这两步操作，所以当前通常是使用 Lua 脚本来执行解锁操作，Redis 会保证脚本里的内容执行是一个原子操作。</p><p>脚本代码如下，逻辑比较简单：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>两个参数的意义如下：</p><p>KEYS[1]：我们要解锁的 key</p><p>ARGV[1]：我们加锁时的 value，用于判断当“锁”是否还是我们持有，如果被其他线程持有了，value 就会发生变化。</p><p>上述方法是 Redis 当前实现分布式锁的主流方法，但是有一个问题，<strong>Redis 分布式锁过期了，还没处理完怎么办？</strong></p><p>首先，我们在设置过期时间时要结合业务场景去考虑，尽量设置一个比较合理的值，就是理论上正常处理的话，在这个过期时间内是一定能处理完毕的。之后，我们再来考虑对这个问题进行兜底设计。</p><p>关于这个问题，目前常见的解决方法有两种：</p><p>1、守护线程“续命”：额外起一个线程，定期检查线程是否还持有锁，如果有则延长过期时间。Redisson 里面就实现了这个方案，使用“看门狗”定期检查（每1/3的锁时间检查1次），如果线程还持有锁，则刷新过期时间。</p><p>2、超时回滚：当我们解锁时发现锁已经被其他线程获取了，说明此时我们执行的操作已经是“不安全”的了，此时需要进行回滚，并返回失败。同时，需要进行告警，人为介入验证数据的正确性，然后找出超时原因，是否需要对超时时间进行优化等等。</p><p>Redisson 使用看门狗（守护线程）“续命”的方案在大多数场景下是挺不错的，也被广泛应用于生产环境，但是在极端情况下还是会存在问题。</p><p>问题例子如下：</p><p>1、线程1首先获取锁成功，将键值对写入 redis 的 master 节点</p><p>2、在 redis 将该键值对同步到 slave 节点之前，master 发生了故障</p><p>3、redis 触发故障转移，其中一个 slave 升级为新的 master</p><p>4、此时新的 master 并不包含线程1写入的键值对，因此线程2尝试获取锁也可以成功拿到锁</p><p>5、此时相当于有两个线程获取到了锁，可能会导致各种预期之外的情况发生，例如最常见的脏数据</p><p>解决方法：上述问题的根本原因主要是由于 redis 异步复制带来的数据不一致问题导致的，因此解决的方向就是保证数据的一致。</p><p>当前比较主流的解法和思路有两种：</p><p>1）Redis 作者提出的 RedLock；</p><p>2）Zookeeper 实现的分布式锁。</p><p>接下来介绍下这两种方案。</p><h4 id="RedLock"><a href="#RedLock" class="headerlink" title="RedLock"></a><strong>RedLock</strong></h4><p>首先，该方案也是基于文章开头的那个方案（set加锁、lua脚本解锁）进行改良的，所以 antirez 只描述了差异的地方，大致方案如下：假设我们有 N 个 Redis 主节点，例如 N = 5，这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统，为了取到锁，客户端应该执行以下操作:</p><ol><li>获取当前时间，以毫秒为单位</li><li>依次尝试从5个实例，使用相同的 key 和随机值（例如UUID）获取锁。当向Redis 请求获取锁时，客户端应该设置一个超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在 5-50 毫秒之间。这样可以防止客户端在试图与一个宕机的 Redis 节点对话时长时间处于阻塞状态。如果一个实例不可用，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li><li>客户端通过当前时间减去步骤1记录的时间来计算获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且获取锁使用的时间小于锁失效时间时，锁才算获取成功。</li><li>如果取到了锁，其有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）</li><li>如果由于某些原因未能获得锁（无法在至少N/2+1个Redis实例获取锁、或获取锁的时间超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li></ol><p>可以看出，该方案为了解决数据不一致的问题，直接舍弃了异步复制，只使用 master 节点，同时由于舍弃了 slave，为了保证可用性，引入了 N 个节点，官方建议是 5。</p><p>该方案看着挺美好的，但是实际上我所了解到的在实际生产上应用的不多，主要有两个原因：</p><ul><li>该方案的成本似乎有点高，需要使用5个实例；</li></ul><ul><li>该方案一样存在问题。</li></ul><p>该方案主要存以下问题：</p><ul><li>严重依赖系统时钟。如果线程1从3个实例获取到了锁，但是这3个实例中的某个实例的系统时间走的稍微快一点，则它持有的锁会提前过期被释放，当他释放后，此时又有3个实例是空闲的，则线程2也可以获取到锁，则可能出现两个线程同时持有锁了。</li></ul><ul><li>如果线程1从3个实例获取到了锁，但是万一其中有1台重启了，则此时又有3个实例是空闲的，则线程2也可以获取到锁，此时又出现两个线程同时持有锁了。</li></ul><h3 id="Zookeeper-实现分布式锁"><a href="#Zookeeper-实现分布式锁" class="headerlink" title="Zookeeper 实现分布式锁"></a><strong>Zookeeper 实现分布式锁</strong></h3><p><strong>zookeeper的特性</strong></p><ul><li>有序节点：假如当前有一个父节点为/lock，我们可以在这个父节点下面创建子节点；zookeeper提供了一个可选的有序特性，例如我们可以创建子节点“<code>/lock/node-</code>”并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号，也就是说如果是第一个创建的子节点，那么生成的子节点为<code>/lock/node-0000000000</code>，下一个节点则为<code>/lock/node-0000000001</code>，依次类推。</li><li>临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。</li><li>事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：<br>1.节点创建；<br>2.节点删除；<br>3.节点数据修改；<br>4.子节点变更。</li></ul><p>Zookeeper 的分布式锁实现方案如下：</p><p>1、创建一个锁目录 /locks，该节点为持久节点</p><p>2、想要获取锁的线程都在锁目录下创建一个临时顺序节点</p><p>3、获取锁目录下所有子节点，对子节点按节点自增序号从小到大排序</p><p>4、判断本节点是不是第一个子节点，如果是，则成功获取锁，开始执行业务逻辑操作；如果不是，则监听自己的上一个节点的删除事件</p><p>5、持有锁的线程释放锁，只需删除当前节点即可。</p><p>6、当自己监听的节点被删除时，监听事件触发，则回到第3步重新进行判断，直到获取到锁。</p><p>由于 Zookeeper 保证了数据的强一致性，因此不会存在之前 Redis 方案中的问题，整体上来看还是比较不错的。</p><p>Zookeeper 方案的主要问题在于性能不如 Redis 那么好，当申请锁和释放锁的频率较高时，会对集群造成压力，此时集群的稳定性可用性能可能又会遭受挑战。</p><p><strong>分布式锁的选型</strong></p><p>当前主流的方案有两种：</p><ul><li><p>Redis 的 set 加锁+lua 脚本解锁方案，至于是不是用守护线程续命可以结合自己的场景去决定，个人建议还是可以使用的。</p></li><li><p>Zookeeper 方案</p></li></ul><p>通常情况下，对于数据的安全性要求没那么高的，可以采用 Redis 的方案，对数据安全性要求比较高的可以采用 Zookeeper 的方案。</p>]]></content>
    
    
    <summary type="html">想让同一时刻只有一个线程在执行某段代码，或者说控制资源在同一时刻只能被一个线程持有并操作，这个时候需要锁。以淘宝双11为例，在0点这一刻，如果有几十万甚至上百万的人同时去查看某个商品的详情，这时候会触发商品的查询，如果我们不做控制，全部走到数据库去，那是有可能直接将数据库打垮的。这个时候一个比较常用的做法就是进行加锁，只让1个线程去查询，其他线程待等待这个线程的查询结果后，直接拿结果。在这个例子中，锁用于控制访问数据库的流量，最终起到了保护系统的作用。</summary>
    
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/categories/redis/"/>
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/tags/redis/"/>
    
    <category term="分布式锁" scheme="https://gaoxing27.gitee.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>redis-持久化机制</title>
    <link href="https://gaoxing27.gitee.io/2021/05/23/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/"/>
    <id>https://gaoxing27.gitee.io/2021/05/23/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/</id>
    <published>2021-05-23T13:24:56.000Z</published>
    <updated>2021-06-30T10:40:57.491Z</updated>
    
    <content type="html"><![CDATA[<p>Redis是一个内存数据库，数据可以持久化到磁盘。有了持久化方案，Redis就可以对数据进行备份、恢复、复制。Redis提供了两种持久化方案：RDB和AOF。在Redis 4.0中，提供了一个新特性：两者的混合持久化。</p><p>RDB是一种快照存储持久化方式，具体就是当达到触发条件时，Redis可以将内存中的数据以二进制的形式，保存到硬盘的文件当中，默认保存的文件名为dump.rdb，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据。</p><h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p>开启RDB持久化方式很简单，客户端可以通过向Redis服务器发送save或bgsave命令让服务器生成rdb文件，或者通过服务器配置文件指定触发RDB条件。</p><ol><li><strong>save命令</strong></li></ol><p>save命令是一个同步操作。当客户端向服务器发送save命令请求进行持久化时，服务器会阻塞save命令之后的其他客户端的请求，直到数据同步完成。</p><p>如果数据量太大，同步数据会执行很久，而这期间Redis服务器也无法接收其他请求，所以，最好不要在生产环境使用save命令</p><ol start="2"><li><strong>bgsave</strong></li></ol><p>与save命令不同，bgsave命令是一个异步操作。</p><p>当客户端发服务发出bgsave命令时，Redis服务器主进程会forks一个子进程来数据同步问题，在将数据保存到rdb文件之后，子进程会退出。</p><p>所以，与save命令相比，Redis服务器在处理bgsave采用子线程进行IO写入，而主进程仍然可以接收其他请求，但forks子进程是同步的，所以forks子进程时，一样不能接收其他请求，这意味着，如果forks一个子进程花费的时间太久(一般是很快的)，bgsave命令仍然有阻塞其他客户的请求的情况发生。</p><ol start="3"><li><strong>服务器配置自动触发</strong></li></ol><p>除了通过客户端发送命令外，还有一种方式，就是在Redis配置文件中的save指定到达触发RDB持久化的条件，比如【多少秒内至少达到多少写操作】就开启RDB数据同步。</p><p>例如我们可以在配置文件redis.conf指定如下的选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 900s内至少达到一条写命令</span><br><span class="line">save 900 1</span><br><span class="line"># 300s内至少达至10条写命令</span><br><span class="line">save 300 10</span><br><span class="line"># 60s内至少达到10000条写命令</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><p>这种通过服务器配置文件触发RDB的方式，与bgsave命令类似，达到触发条件时，会forks一个子进程进行数据同步，不过最好不要通过这方式来触发RDB持久化，因为设置触发的时间太短，则容易频繁写入rdb文件，影响服务器性能，时间设置太长则会造成数据丢失。</p><p>前面介绍了三种让服务器生成rdb文件的方式，无论是由主进程生成还是子进程来生成，其过程如下：</p><ul><li>生成临时rdb文件，并写入数据。</li><li>完成数据写入，用临时文代替代正式rdb文件。</li><li>删除原来的db文件。</li></ul><p>RDB默认生成的文件名为dump.rdb，当然，我可以通过配置文件进行更加详细配置，比如在单机下启动多个redis服务器进程时，可以通过端口号配置不同的rdb名称，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 是否压缩rdb文件</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line"># rdb文件的名称</span><br><span class="line">dbfilename redis-6379.rdb</span><br><span class="line"></span><br><span class="line"># rdb文件保存目录</span><br><span class="line">dir ~&#x2F;redis&#x2F;</span><br></pre></td></tr></table></figure><p><strong>RDB的几个优点</strong></p><ul><li>与AOF方式相比，通过rdb文件恢复数据比较快。</li><li>rdb文件非常紧凑，适合于数据备份。</li><li>通过RDB进行数据备，由于使用子进程生成，所以对Redis服务器性能影响较小。</li></ul><p><strong>RDB的几个缺点</strong></p><ul><li>如果服务器宕机的话，采用RDB的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。</li><li>使用save命令会造成服务器阻塞，直接数据同步完成才能接收后续请求。</li><li>使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。</li></ul><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>聊完了RDB,来聊聊Redis的另外一个持久化方式：AOF(Append-only file)。</p><p>与RDB存储某个时刻的快照不同，AOF持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以Redis协议追加保存到以后缀为aof文件末尾，在Redis服务器重启时，会加载并运行aof文件的命令，以达到恢复数据的目的。</p><p><strong>开启AOF持久化方式</strong></p><p>Redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置，如下面的redis.conf文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 开启aof机制</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># aof文件名</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line"># 写入策略,always表示每个写操作都保存到aof文件中,也可以是everysec或no</span><br><span class="line">appendfsync always</span><br><span class="line"></span><br><span class="line"># 默认不重写aof文件</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># 保存目录</span><br><span class="line">dir ~&#x2F;redis&#x2F;</span><br></pre></td></tr></table></figure><p><strong>三种写入策略</strong></p><p>在上面的配置文件中，我们可以通过appendfsync选项指定写入策略,有三个选项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always</span><br><span class="line"># appendfsync everysec</span><br><span class="line"># appendfsync no</span><br></pre></td></tr></table></figure><ol><li><strong>always</strong></li></ol><p>客户端的每一个写操作都保存到aof文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢。</p><ol start="2"><li><strong>everysec</strong></li></ol><p>appendfsync的默认写入策略，每秒写入一次aof文件，因此，最多可能会丢失1s的数据。</p><ol start="3"><li><strong>no</strong></li></ol><p>Redis服务器不负责写入aof，而是交由操作系统来处理什么时候写入aof文件。更快，但也是最不安全的选择，不推荐使用。</p><p><strong>AOF文件重写</strong></p><p>AOF将客户端的每一个写操作都追加到aof文件末尾，比如对一个key多次执行incr命令，这时候，aof保存每一次命令到aof文件中，aof文件会变得非常大。</p><p>aof文件太大，加载aof文件恢复数据时，就会非常慢，为了解决这个问题，Redis支持aof文件重写，通过重写aof，可以生成一个恢复当前数据的最少命令集，比如上面的例子中那么多条命令，可以重写为：</p><p>aof文件是一个二进制文件，并不是像上面的例子一样，直接保存每个命令，而使用Redis自己的格式，上面只是方便演示。</p><p><strong>两种重写方式</strong></p><p>通过在redis.conf配置文件中的选项no-appendfsync-on-rewrite可以设置是否开启重写，这种方式会在每次fsync时都重写，影响服务器性以，因此默认值为no，不推荐使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 默认不重写aof文件</span><br><span class="line">no-appendfsync-on-rewrite no</span><br></pre></td></tr></table></figure><p>客户端向服务器发送bgrewriteaof命令，也可以让服务器进行AOF重写。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 让服务器异步重写追加aof文件命令</span><br><span class="line">&gt; bgrewriteaof</span><br></pre></td></tr></table></figure><p>AOF重写方式也是异步操作，即如果要写入aof文件，则Redis主进程会forks一个子进程来处理，如下所示：</p><p>重写aof文件的好处</p><ul><li>压缩aof文件，减少磁盘占用量。</li><li>将aof的命令压缩为最小命令集，加快了数据恢复的速度。</li></ul><p><strong>AOF文件损坏</strong></p><p>在写入aof日志文件时，如果Redis服务器宕机，则aof日志文件文件会出格式错误，在重启Redis服务器时，Redis服务器会拒绝载入这个aof文件，可以通过以下步骤修复aof并恢复数据。</p><p>1、备份现在aof文件，以防万一。</p><p>2、使用redis-check-aof命令修复aof文件，该命令格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 修复aof日志文件</span><br><span class="line">$ redis-check-aof -fix file.aof</span><br></pre></td></tr></table></figure><p>3、重启Redis服务器，加载已经修复的aof文件，恢复数据。</p><p><strong>AOF的优点</strong></p><ul><li>AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较少。</li></ul><p><strong>AOF的缺点</strong></p><ul><li>AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。</li><li>恢复数据的速度比RDB慢。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过下面的表示，我们可以从几个方面对比一下RDB与AOF,在应用时，要根本自己的实际需求，选择RDB或者AOF，其实，如果想要数据足够安全，可以两种方式都开启，但两种持久化方式同时进行IO操作，会严重影响服务器性能，因此有时候不得不做出选择。</p><p><img src="/images/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/rdb%E5%92%8Caof%E5%AF%B9%E6%AF%94.png" alt="rdb和aof对比"></p><p>当RDB与AOF两种方式都开启时，Redis会优先使用AOF日志来恢复数据，因为AOF保存的文件比RDB文件更完整。</p><blockquote><p>引用<br><a href="https://juejin.cn/post/6844903949527416845">https://juejin.cn/post/6844903949527416845</a></p></blockquote>]]></content>
    
    
    <summary type="html">Redis是一个内存数据库，数据可以持久化到磁盘。有了持久化方案，Redis就可以对数据进行备份、恢复、复制。 Redis提供了两种持久化方案：RDB和AOF。在Redis 4.0中，提供了一个新特性：两者的混合持久化。</summary>
    
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/categories/redis/"/>
    
    
    <category term="redis" scheme="https://gaoxing27.gitee.io/tags/redis/"/>
    
  </entry>
  
</feed>
